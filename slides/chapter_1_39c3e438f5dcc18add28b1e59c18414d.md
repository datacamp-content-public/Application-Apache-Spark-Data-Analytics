---
key: 39c3e438f5dcc18add28b1e59c18414d
title: 'Insert title here'
---

## Overview of what you will accomplish

```yaml
type: TitleSlide
key: 543d37a887
```

`@lower_third`
name: Full Name
title: Instructor

`@script`


---

## Overview

```yaml
type: FullCodeSlide
key: d34c9a9baf
```

`@part1`
1. pyspark.ml.feature
2. pyspark.ml.classification

`@script`
Build, fit, and evaluate a classifier model using high dimension sparse data.

We will use two Spark.ML modules. The first one for transforming the data into the form that the classifier expects. The second is a machine learning library called a classification model.

Even though the data is very sparse, because we have enough of it, it is possible to predict the class membership for many users with just a handful of data. 

To transform the text data into an array of integers we use a module from pyspark.ml.feature library called CountVectorizer. This module wants an array of strings as its input and doesn't like null values, so we need to perform some cleanup on the data to prep it for the transform step. 

To build the classifier we use a module from pyspark.ml.classification, LogisticRegression.  You will also encounter two other modules from pyspark.ml.classification, LogisticRegressionModel and LogisticRegressionSummary.

---

## What you will accomplish

```yaml
type: FullCodeSlide
key: a78fae1244
```

`@part1`
1. Load a transactional log file
2. Extract feature data from the log file data
3. Analyze the data 
3. Transform the data into feature data
4. Split the data for training and evaluation
5. Select the feature and label data
6. Fit a classification model 
7. Evaluate the trained model on test data
7. Tune the model

`@script`
1. Load a transactional log file into a dataframe.
2. Extract feature data from the log file data.
	2. Convert comma delimited fields into array of strings format.
	2. Handle null and empty values.
3. Analyze the data to determine whether it is suitable for training a classification model.
3. Transform the data into feature data suitable for training a machine learning model.
4. Split the data into training and test sets.
5. Transform the feature and label columns to the format expected by the machine learning model.
6. Fit a classification model on the training data and 
7. evaluate it on the test data.
7. Tune the model

---

## What is special about this dataset

```yaml
type: FullSlide
key: c6fa7dce97
```

`@part1`


`@script`


---

## Rabbit vs Duck

```yaml
type: FullImageSlide
key: 839a76096d
```

`@part1`


`@script`


---

## Let's practice!

```yaml
type: FinalSlide
key: 7ee0349cf9
```

`@script`
