---
title: 'Insert title here'
key: 3c3ec6dec8f48898b3b494b8e5e8720e
video_link:
    mp3: 'http://assets.datacamp.com/production/repositories/3679/datasets/bb79f4b0d385311a5f68589ab39fd541c9cacd8b/lesson1.1.mp3'
---

## Spark SQL

```yaml
type: TitleSlide
key: fdc04c3654
```

`@lower_third`
name: Mark Plutowski Phd
title: Algorithmic Econometrician

`@script`
Hello and welcome to this lesson about Spark SQL.

---

## Load dataframe from file

```yaml
type: FullCodeSlide
key: 896eab7eca
center_content: false
```

`@part1`
```
>>> df = spark.read.csv("trainsched.txt",header=True)
```

```
>>> df.show()
+--------+-------------+-----+
|train_id|      station| time|
+--------+-------------+-----+
|     324|San Francisco|7:59a|
|     324|  22nd Street|8:03a|
|     324|     Millbrae|8:16a|
|     324|    Hillsdale|8:24a|
|     324| Redwood City|8:31a|
|     324|    Palo Alto|8:37a|
|     324|     San Jose|9:05a|
|     217|       Gilroy|6:06a|
|     217|   San Martin|6:15a|
|     217|  Morgan Hill|6:21a|
|     217| Blossom Hill|6:36a|
|     217|      Capitol|6:42a|
|     217|       Tamien|6:50a|
|     217|     San Jose|6:59a|
+--------+-------------+-----+
```

`@script`
In this lesson you will see how to create a SQL table from a dataframe,

---

## Create SQL table and query it

```yaml
type: FullCodeSlide
key: c8fd352071
```

`@part1`
```
df.createOrReplaceTempView("df")
```

```
spark.sql("select * from df where station = 'San Jose'")
     .show()
+--------+--------+-----+
|train_id| station| time|
+--------+--------+-----+
|     324|San Jose|9:05a|
|     217|San Jose|6:59a|
+--------+--------+-----+

```
{{1}}

`@script`
and then query it.

---

## Dataframe

```yaml
type: FullImageSlide
key: da4bd71079
```

`@part1`
![Frame](http://assets.datacamp.com/production/repositories/3679/datasets/502d62ac2ce6678c50b2bd216efcbe2ff54844a5/Frame.png)

`@script`
The dataframe is a fundamental data abstraction in Spark.

---

## Dataframe

```yaml
type: FullImageSlide
key: 682b45c3eb
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/5fe9d0117a1dbf3be4a43011a861e635b1bd919a/FrameData.png)

`@script`
A Spark DataFrame is a distributed collection of data organized into named columns.

---

## Tabular data

```yaml
type: FullCodeSlide
key: 7bfd28d821
```

`@part1`
```
+--------+-------------+-----+
|train_id|      station| time|
+--------+-------------+-----+
|     324|San Francisco|7:59a| 
|     324|  22nd Street|8:03a|
|     324|     Millbrae|8:16a|
|     324|    Hillsdale|8:24a|
|     324| Redwood City|8:31a|
|     324|    Palo Alto|8:37a|
|     324|     San Jose|9:05a|
|     217|       Gilroy|6:06a|
|     217|   San Martin|6:15a|
|     217|  Morgan Hill|6:21a|
|     217| Blossom Hill|6:36a|
|     217|      Capitol|6:42a|
|     217|       Tamien|6:50a|
|     217|     San Jose|6:59a|
+--------+-------------+-----+
```

`@script`
It is conceptually equivalent to a table in a relational database, also called, simply, “tabular” data.

---

## Tabular data

```yaml
type: FullCodeSlide
key: 3805ea0e85
disable_transition: true
```

`@part1`
```
+--------+-------------+-----+
|train_id|      station| time|
+--------+-------------+-----+
|     324|San Francisco|7:59a|  <====
|     324|  22nd Street|8:03a|
|     324|     Millbrae|8:16a|
|     324|    Hillsdale|8:24a|
|     324| Redwood City|8:31a|
|     324|    Palo Alto|8:37a|
|     324|     San Jose|9:05a|
|     217|       Gilroy|6:06a|
|     217|   San Martin|6:15a|
|     217|  Morgan Hill|6:21a|
|     217| Blossom Hill|6:36a|
|     217|      Capitol|6:42a|
|     217|       Tamien|6:50a|
|     217|     San Jose|6:59a|
+--------+-------------+-----+
```

`@script`
Tabular data comprises a data structure representing one or more rows,

---

## Tabular data

```yaml
type: FullCodeSlide
key: 51a1235db6
disable_transition: true
```

`@part1`
```
+--------+-------------+-----+
|train_id|      station| time|
+--------+-------------+-----+
|     324|San Francisco|7:59a|
|     324|  22nd Street|8:03a|  <====
|     324|     Millbrae|8:16a|
|     324|    Hillsdale|8:24a|
|     324| Redwood City|8:31a|
|     324|    Palo Alto|8:37a|
|     324|     San Jose|9:05a|
|     217|       Gilroy|6:06a|
|     217|   San Martin|6:15a|
|     217|  Morgan Hill|6:21a|
|     217| Blossom Hill|6:36a|
|     217|      Capitol|6:42a|
|     217|       Tamien|6:50a|
|     217|     San Jose|6:59a|
+--------+-------------+-----+
```

`@script`
also called “records”, each of which consists of a number of measurements,

---

## Tabular data

```yaml
type: FullCodeSlide
key: 1c45bde994
disable_transition: true
```

`@part1`
```
+--------+-------------+-----+
|train_id|      station| time|
+--------+-------------+-----+
|     324|San Francisco|7:59a|
|     324|  22nd Street|8:03a|
|     324|     Millbrae|8:16a|  <====
|     324|    Hillsdale|8:24a|
|     324| Redwood City|8:31a|
|     324|    Palo Alto|8:37a|
|     324|     San Jose|9:05a|
|     217|       Gilroy|6:06a|
|     217|   San Martin|6:15a|
|     217|  Morgan Hill|6:21a|
|     217| Blossom Hill|6:36a|
|     217|      Capitol|6:42a|
|     217|       Tamien|6:50a|
|     217|     San Jose|6:59a|
+--------+-------------+-----+
```

`@script`


---

## Tabular data

```yaml
type: FullCodeSlide
key: a00079719d
disable_transition: true
```

`@part1`
```
+--------+-------------+-----+
|train_id|      station| time|
+--------+-------------+-----+
|     324|San Francisco|7:59a|
|     324|  22nd Street|8:03a|
|     324|     Millbrae|8:16a|  
|     324|    Hillsdale|8:24a|  <====
|     324| Redwood City|8:31a|
|     324|    Palo Alto|8:37a|
|     324|     San Jose|9:05a|
|     217|       Gilroy|6:06a|
|     217|   San Martin|6:15a|
|     217|  Morgan Hill|6:21a|
|     217| Blossom Hill|6:36a|
|     217|      Capitol|6:42a|
|     217|       Tamien|6:50a|
|     217|     San Jose|6:59a|
+--------+-------------+-----+
```

`@script`
with each column of each row containing a single measurement. Alternatively, each row may be treated as a single observation of multiple "variables".

---

## Similar to Matrix Data

```yaml
type: FullImageSlide
key: 93560cedcc
disable_transition: true
```

`@part1`
![Matrix Data](http://assets.datacamp.com/production/repositories/3679/datasets/2ae5e7e928cc0338e90b7aa73f1f556929cf990d/matrix_.png)

`@script`
"tabular" data is similar to a matrix or array,

---

## Matrix data

```yaml
type: FullImageSlide
key: 8893c47c8a
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/c7fbdcda6da2a4fff0f4c133b2f1b2cc24b32465/matrix_row.png)

`@script`
but unlike matrices, where each row and column contain the same type of data,

---

## Matrix data

```yaml
type: FullImageSlide
key: 9123f20d3a
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/049846ac5086f5391b8cd536d79ed0e926229d90/matrix_rowcol.png)

`@script`


---

## Tabular data

```yaml
type: FullImageSlide
key: 151cf6fe31
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/18775a073971a763eaa6a8c233f29933255bce48/Table_NoHeader.png)

`@script`
each column in a table can be a different data type.

---

## Tabular data

```yaml
type: FullImageSlide
key: 1cb81849ce
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/1063a41918d2d9c84e2f8cef9a770e3329b7917b/Table_NoHeader_Col.png)

`@script`


---

## Tabular data

```yaml
type: FullImageSlide
key: 48b5a88014
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/5a51226fa65049dc7fd8967b7e3ca4777cf5051a/Table_NoHeader_Col2.png)

`@script`


---

## Tabular data with column names

```yaml
type: FullImageSlide
key: eccf0fccd3
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/88a9722bdac722110ddf4b21ee8d08d89d95f909/Table_Header.png)

`@script`
Also unlike matrices, each column can have a name.

---

## Tabular data with column names

```yaml
type: FullImageSlide
key: 3d513f3d76
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/d8750003b001fb81895e8a776c2a484d9255b837/Table_Header_Emph.png)

`@script`


---

## Two dataframes

```yaml
type: FullImageSlide
key: ff55871faf
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/99d6b249647757ac0e7d0b0ab6b5cf168e32c475/2tables.png)

`@script`
You could have two dataframes having the same types of columns, and containing different data.

---

## Two dataframes <===

```yaml
type: FullImageSlide
key: c76ba6b14d
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/e3cab90b9123604712836c6be5909e8cdb5ef4fc/2tables%20arrow.png)

`@script`
You could then concatenate the rows of data in these two tables into a single dataframe.

---

## Two dataframes concatenated

```yaml
type: FullImageSlide
key: 08600288e2
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/f22f5d42b9322b18ddae1fad5da96752c5e1f48f/2tables%20concat.png)

`@script`
We said that “A Spark DataFrame is a distributed collection of data organized into named columns.”  What do we mean by “distributed” ?

---

## Two dataframes (1)

```yaml
type: FullImageSlide
key: 3ebf3f1da4
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/8b7f761e7b0eb30d1f37eaef9a3cb2d87a43adc7/2tables_1.png)

`@script`


---

## Two dataframes (2)

```yaml
type: FullImageSlide
key: 8fb42b2997
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/14a486d7b99cc45fdce07c5c177d86bae850c713/2tables_3.png)

`@script`


---

## Two dataframes (3)

```yaml
type: FullImageSlide
key: cf48b66e72
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/98a53fe820ff642c45eff6eb3da2dfaf59293e5e/2tables_2.png)

`@script`


---

## Two dataframes (4)

```yaml
type: FullImageSlide
key: 45f0144d2b
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/bed838aff129151a66d5bdbb0b43931fc1b6eb3c/2tables_4.png)

`@script`


---

## Two dataframes (5)

```yaml
type: FullImageSlide
key: f6eb6eda8f
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/ba7bf6b008eba85f824e49c0a85047d3b0997956/2tables_5.png)

`@script`


---

## Two dataframes (6)

```yaml
type: FullImageSlide
key: b215237eb6
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/99d6b249647757ac0e7d0b0ab6b5cf168e32c475/2tables_6.png)

`@script`
Spark can split this dataset into parts, then store each part on different servers. In this case, Spark is partitioning the data and distributing it automatically, on your behalf.

---

## Two dataframes - distributed

```yaml
type: FullImageSlide
key: e44770556a
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/e9e6721be2b34312f06804734d5525e1eb84eba7/2tables_distrd.png)

`@script`
This is one technique that Spark uses to handle large datasets, even though each server may not have enough storage to hold the entire dataset on its own.  What’s more, Spark allows you to treat a dataframe like a table, and query it using SQL.

---

## SQL

```yaml
type: FullImageSlide
key: 7cd5b425b2
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/d8850f590399d082ae4f714e91edcda639029022/SQL.png)

`@script`
Now, What is SQL?

---

## Structured Query Language

```yaml
type: FullImageSlide
key: 80fe098456
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/bb23ad148a47c090085b93645cb5b185c87462ef/StructQueryLang.png)

`@script`
SQL stands for “Structured Query Language”, and is a common way of fetching data from one or more tables.

---

## Querying

```yaml
type: FullImageSlide
key: fea363d2ae
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/7d2edf9114514533c19ccc86dc7ca5824adf8093/Caltrain_324_with_query.png)

`@script`
This fetching process is called “querying” and the statement you use to tell the computer what to fetch is called a “query”.

---

## Distributed data

```yaml
type: FullImageSlide
key: 3882dd2d96
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/7b2b1a5e011b91d347536b853ee6aa6824ccb96d/Records.png)

`@script`
What’s useful about the Spark SQL table is that it allows you to take the data that is in a dataframe -- namely, a distributed collection of rows having named columns -- and treat it as a single table,

---

## Distributed data + query

```yaml
type: FullImageSlide
key: 40274c607e
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/89e58f20b8d56fd73433d874ac42f4b6bf4685c6/Records_Query.png)

`@script`
and fetch data from it using an SQL query.

---

## Pyspark

```yaml
type: FullImageSlide
key: 9fa39a6c92
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/2877bd2dd54a67c74c450b48d98da148d8f4457b/Pyspark.png)

`@script`
Let’s load some data into a dataframe, convert it into a sql table, and query it.

---

## Pyspark cursor

```yaml
type: FullImageSlide
key: 7b03c4fd5f
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/e4007faf17b199c485ea36869ed8a423f8cac07c/Pyspark_cursor.png)

`@script`


---

## Pyspark

```yaml
type: FullImageSlide
key: 7d5e2b043e
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/2877bd2dd54a67c74c450b48d98da148d8f4457b/Pyspark.png)

`@script`


---

## Pyspark cursor

```yaml
type: FullImageSlide
key: bb28c88cda
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/e4007faf17b199c485ea36869ed8a423f8cac07c/Pyspark_cursor.png)

`@script`


---

## Pyspark

```yaml
type: FullImageSlide
key: ffcee958ba
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/2877bd2dd54a67c74c450b48d98da148d8f4457b/Pyspark.png)

`@script`


---

## Pyspark cursor

```yaml
type: FullImageSlide
key: 838bf0f52d
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/e4007faf17b199c485ea36869ed8a423f8cac07c/Pyspark_cursor.png)

`@script`


---

## Pyspark

```yaml
type: FullImageSlide
key: c3bdcf0a89
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/2877bd2dd54a67c74c450b48d98da148d8f4457b/Pyspark.png)

`@script`


---

## Pyspark cursor

```yaml
type: FullImageSlide
key: 9c636d8870
disable_transition: true
```

`@part1`
![](http://assets.datacamp.com/production/repositories/3679/datasets/e4007faf17b199c485ea36869ed8a423f8cac07c/Pyspark_cursor.png)

`@script`


---

## Let's practice

```yaml
type: FinalSlide
key: e3a3d5eb33
```

`@script`
