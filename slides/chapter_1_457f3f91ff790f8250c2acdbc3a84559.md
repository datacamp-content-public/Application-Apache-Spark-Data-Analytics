---
title: Insert title here
key: 457f3f91ff790f8250c2acdbc3a84559

---
## Window Function SQL

```yaml
type: "TitleSlide"
key: "4d47258445"
```

`@lower_third`

name: Mark Plutowski
title: Algorithmic Econometrician


`@script`
Hello and welcome, to this lesson on Spark SQL, where you will learn about window functions. What is Window Function SQL and how is it useful?  SQL window functions express certain very useful operations more simply than regular dataframe dot-notation or regular SQL queries.  When processing some rows, each row can use the values of other rows in calculating its value.


---
## A train schedule

```yaml
type: "FullImageSlide"
key: "9f65f2908c"
```

`@part1`
![Caltrain schedule 324 line](http://assets.datacamp.com/production/repositories/3679/datasets/0fe76393810cf5313c0fec69f7235783d040c82a/Caltrain%20324.png)


`@script`
Suppose you have a table containing a train schedule for a train line.   You could use a window function to calculate the time until the next stop and add that as a new column, like so:


---
## Column with time **until** next stop added

```yaml
type: "FullImageSlide"
key: "f79a469ba9"
```

`@part1`
![Caltrain next stop](http://assets.datacamp.com/production/repositories/3679/datasets/1b48cb2a0a7343659839149f49174755c5e57361/Caltrain%20324%20nextstop.png)


`@script`
A Window function operates on a set of rows and returns a value for each row in the set -- but now this value can depend on other rows in the set. The term window describes the set of rows on which the function operates.  The value returned for each row can be a value from one of the rows in the “window”, or, a value from a “window function” that uses values from the rows in the window to calculate its value. 
Let's simplify this example to to demonstrate what this means.


---
## Column with time **of** next stop.

```yaml
type: "FullImageSlide"
key: "617a00ca44"
```

`@part1`
![Colum](http://assets.datacamp.com/production/repositories/3679/datasets/292ebf81bd35c933a3f83c7c9453049f70211413/Caltrain%20324%20following.png)


`@script`
Here, a window function sql query looked at the current row and the next row, adding a column giving the value of the time column for the following row. Note that in the last row, the value of the new column is empty -- that is because there is no following row. Let's look at some code for achieving this result.


---
## OVER clause and ORDER BY clause

```yaml
type: "FullCodeSlide"
key: "d03af0ba0d"
```

`@part1`
```
>>> query = """
... select 
...   train_id, 
...   station, 
...   time, 
...   lead(time,1) over (order by time) as time_next 
... from sched 
... where train_id=324 """
```

```
>>> spark.sql(query).show()
+--------+-------------+-----+---------+
|train_id|      station| time|time_next|
+--------+-------------+-----+---------+
|     324|San Francisco|7:59a|    8:03a|
|     324|  22nd Street|8:03a|    8:16a|
|     324|     Millbrae|8:16a|    8:24a|
|     324|    Hillsdale|8:24a|    8:31a|
|     324| Redwood City|8:31a|    8:37a|
|     324|    Palo Alto|8:37a|    9:05a|
|     324|     San Jose|9:05a|     null|
+--------+-------------+-----+---------+
```


`@script`
Now we will see how a window function in this query is able to access more than just the current row, using a specific example.  Take a look at this query. 

In this query, I put each column on a separate line to make it more clear -- note the column having the OVER clause -- adding a OVER clause designates this query as a window function query. The over clause must contain an ORDER BY clause that tells it how to sequence the rows. 

The LEAD function lets you query more than one row in a table at a time without having to join the table to itself. In this case, it returns the value of the time column from the next row in the table.

Notice how the query constrains the table to only look at rows where train_id=324.  I'm now going to remove that constraint.


---
## PARTITION BY clause

```yaml
type: "FullCodeSlide"
key: "ebb658e741"
```

`@part1`
```
>>> query = """
... select 
...   train_id, 
...   station, 
...   time, 
...   lead(time,1) over (partition by train_id order by time) as time_next 
... from sched 
"""
```


`@script`
This query removes the constraint on train_id that was in the previous query, and adds a PARTITION BY clause inside the OVER clause.  What do you think the result will be? Let's find out.


---
## Result of adding PARTITION BY clause

```yaml
type: "FullCodeSlide"
key: "b5f9a7e716"
```

`@part1`
```
+--------+-------------+-----+---------+
|train_id|      station| time|time_next|
+--------+-------------+-----+---------+
|     217|       Gilroy|6:06a|    6:15a|
|     217|   San Martin|6:15a|    6:21a|
|     217|  Morgan Hill|6:21a|    6:36a|
|     217| Blossom Hill|6:36a|    6:42a|
|     217|      Capitol|6:42a|    6:50a|
|     217|       Tamien|6:50a|    6:59a|
|     217|     San Jose|6:59a|     null|
|     324|San Francisco|7:59a|    8:03a|
|     324|  22nd Street|8:03a|    8:16a|
|     324|     Millbrae|8:16a|    8:24a|
|     324|    Hillsdale|8:24a|    8:31a|
|     324| Redwood City|8:31a|    8:37a|
|     324|    Palo Alto|8:37a|    9:05a|
|     324|     San Jose|9:05a|     null|
+--------+-------------+-----+---------+
```


`@script`
Once you have the time of the current row and the next row together within the same row, it is straightforward for standard sql to calculate the difference.


---
## Time to next stop

```yaml
type: "FullImageSlide"
key: "75ab269be2"
```

`@part1`
![Caltrain next stop](http://assets.datacamp.com/production/repositories/3679/datasets/1b48cb2a0a7343659839149f49174755c5e57361/Caltrain%20324%20nextstop.png)


`@script`
The time to next stop column contains the difference between the time of the current row and the time of the next row. At this point you should now be able to obtain this result from what we've covered in this lesson.


---
## Let's apply what we've learned

```yaml
type: "FinalSlide"
key: "595b2d997a"
```

`@script`
Let's see how to get this result.

