---
title: Insert title here
key: 457f3f91ff790f8250c2acdbc3a84559

---
## Window Function SQL

```yaml
type: "TitleSlide"
key: "4d47258445"
```

`@lower_third`

name: Mark Plutowski
title: Algorithmic Econometrician


`@script`
Hello and welcome, to this lesson on Spark SQL, where you will learn about window functions. 

As a prerequisite you should by now know how to convert Spark dataframes into an SQL table and run SQL queries on such a table. 

What is a window function?


---
## A train schedule

```yaml
type: "FullImageSlide"
key: "9f65f2908c"
```

`@part1`
![Caltrain schedule 324 line](http://assets.datacamp.com/production/repositories/3679/datasets/0fe76393810cf5313c0fec69f7235783d040c82a/Caltrain%20324.png)


`@script`
Suppose you have a table containing a train schedule for a train line.   You could use a window function to calculate the time until the next stop and add that as a new column.


---
## Column with time **until** next stop added

```yaml
type: "FullImageSlide"
key: "f79a469ba9"
```

`@part1`
![Caltrain next stop](http://assets.datacamp.com/production/repositories/3679/datasets/1b48cb2a0a7343659839149f49174755c5e57361/Caltrain%20324%20nextstop.png)


`@script`
Window functions operate on a set of rows and return a value for each row in the set. The term window describes the set of rows on which the function operates.  The value returned for each row can be a value from one of the rows in the “window”, or, a value from a “window function” that uses values from the rows in the window to calculate its value.


---
## Column with time **of** next stop.

```yaml
type: "FullImageSlide"
key: "617a00ca44"
```

`@part1`
![Colum](http://assets.datacamp.com/production/repositories/3679/datasets/292ebf81bd35c933a3f83c7c9453049f70211413/Caltrain%20324%20following.png)


`@script`
A window function sql query looking at the current row and the next row adds a column giving the value of the time column for the following row.  Note that in the last row, the value of the new column is empty -- that is because there is no following row.

Now that each row can easily reference the time of the next row, a regular sql query can now easily calculate a new value given by subtracting the time for the next row from the time of the current row.  Take a few seconds here to mentally subtract the last column from the one before it, that is, the time column, for a few rows.  This is standard fare for a regular sql query, however, note that we also could perform both steps in a single query.


---
## OVER clause and ORDER BY clause

```yaml
type: "FullCodeSlide"
key: "d03af0ba0d"
```

`@part1`
```
>>> query = """
... select 
...   train_id, 
...   station, 
...   time, 
...   lead(time,1) over (order by time) as time_next 
... from sched 
... where train_id=324 """
```

```
>>> spark.sql(query).show()
+--------+-------------+-----+---------+
|train_id|      station| time|time_next|
+--------+-------------+-----+---------+
|     324|San Francisco|7:59a|    8:03a|
|     324|  22nd Street|8:03a|    8:16a|
|     324|     Millbrae|8:16a|    8:24a|
|     324|    Hillsdale|8:24a|    8:31a|
|     324| Redwood City|8:31a|    8:37a|
|     324|    Palo Alto|8:37a|    9:05a|
|     324|     San Jose|9:05a|     null|
+--------+-------------+-----+---------+
```


`@script`
Take a look at this simple window function query. The window function in this query is able to access more than just the current row of the query result. 

In this query, I put each column on a separate line to make it more clear -- note the column having the OVER clause -- adding a OVER clause designates a clause as a window function clause. The over clause must contain an ORDER BY clause that tells it how to sequence the rows. 

The LEAD function lets you query more than one row in a table at a time without having to join the table to itself. In this case, it returns the value of the time column, from the next row in the table.

Notice how the query constrains the table to only look at rows where train_id=324.  I'm now going to remove that constraint. Take another look at the order by clause, because we're going add a PARTITION BY clause inside the OVER clause.


---
## PARTITION BY clause

```yaml
type: "FullCodeSlide"
key: "ebb658e741"
```

`@part1`
```
>>> query = """
... select 
...   train_id, 
...   station, 
...   time, 
...   lead(time,1) over (partition by train_id order by time) as time_next 
... from sched 
"""
```


`@script`
This query removed the constraint on train_id that was in the previous query, and adds a PARTITION BY clause inside the OVER clause.  What do you think the result will be?


---
## Result of adding PARTITION BY clause

```yaml
type: "FullCodeSlide"
key: "b5f9a7e716"
```

`@part1`
```
+--------+-------------+-----+---------+
|train_id|      station| time|time_next|
+--------+-------------+-----+---------+
|     217|       Gilroy|6:06a|    6:15a|
|     217|   San Martin|6:15a|    6:21a|
|     217|  Morgan Hill|6:21a|    6:36a|
|     217| Blossom Hill|6:36a|    6:42a|
|     217|      Capitol|6:42a|    6:50a|
|     217|       Tamien|6:50a|    6:59a|
|     217|     San Jose|6:59a|     null|
|     324|San Francisco|7:59a|    8:03a|
|     324|  22nd Street|8:03a|    8:16a|
|     324|     Millbrae|8:16a|    8:24a|
|     324|    Hillsdale|8:24a|    8:31a|
|     324| Redwood City|8:31a|    8:37a|
|     324|    Palo Alto|8:37a|    9:05a|
|     324|     San Jose|9:05a|     null|
+--------+-------------+-----+---------+
```


`@script`
This query removes the constraint on train_id, and adds a PARTITION BY clause inside the OVER clause.  What do you think the result will be?


---
## Time to next stop

```yaml
type: "FullImageSlide"
key: "75ab269be2"
```

`@part1`
![Caltrain next stop](http://assets.datacamp.com/production/repositories/3679/datasets/1b48cb2a0a7343659839149f49174755c5e57361/Caltrain%20324%20nextstop.png)


`@script`
The time to next stop column contains the difference between the time of the current row and the time of the next row. You could also do this by adding an additional index column and then performing a self-join, however that approach quickly becomes cumbersome when the query is looking at several other rows.


---
## Time series analysis

```yaml
type: "FullImageSlide"
key: "bb44d1cd18"
```

`@part1`
![Trend analysis](http://assets.datacamp.com/production/repositories/3679/datasets/55d231996a24e932400867a1682a4729a54d0658/Ramping%20Quickly.png)


`@script`
Window function sql can be used to calculate running sums, moving averages, and other operations on time series data. It can be used to perform trend detection.


---
## Uptrend analysis

```yaml
type: "FullImageSlide"
key: "a626112bac"
```

`@part1`
![up trend analysis](http://assets.datacamp.com/production/repositories/3679/datasets/57e69cf8859ef48d12264d055e0ca6a6ec7f122b/uptrend%20analysis.png)


`@script`
A window function sql could easily determine whether a time series is flat, as in the topmost figure, or steadily rising, or rising at an accelerating rate.


---
## Anomaly analysis

```yaml
type: "FullImageSlide"
key: "f69dbf48c2"
```

`@part1`
![anomaly analysis](http://assets.datacamp.com/production/repositories/3679/datasets/c6de37daeb40742e01b7977e7120c6a76db8a0f7/anomaly%20analysis.png)


`@script`
An anomaly detection can detect whether a time series contains a datum that is a large departure from neighboring items on the time series.


---
## Final Slide

```yaml
type: "FinalSlide"
key: "595b2d997a"
```

`@script`


